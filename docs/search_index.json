[
["index.html", "User Guide for the Eddie Server Clusters Overview", " User Guide for the Eddie Server Clusters Junfan &amp; GitHub 2022-08-13 Overview The University provides free resources and support for research involving high performance computing (HPC), including multiple server clusters for storing and analyzing data. Find out more information at https://www.wiki.ed.ac.uk/display/ResearchServices/Eddie. This guide will help you access and use the UCSB server clusters effectively. Use cases for HPC include: big data parallel computing lengthy computation times restricted-use data For a broader introduction to HPC with clusters, see the HPC Carpentry’s lessons at https://hpc-carpentry.github.io/, or work through the exercises Please acknowledge the Eddie in publications and presentations if you are using the clusters in your research. "],
["accessing-the-server-clusters.html", "1 Accessing the server clusters 1.1 On campus 1.2 Off campus", " 1 Accessing the server clusters You will naturally be able to use the server clusters as a University member. More tutorial could be found at https://www.wiki.ed.ac.uk/display/ResearchServices/GPUs. The job type selection should probably be Serial or Parallel, but select the option that best describes your needs. In the job type description you should describe any relevant information related to user groups, access to specific folders, or special software usage. If you need Stata, then you should request to be added to the econ group, which holds the license to use Stata. The system to be used should be Pod and Knot, which are the main Linux-based server clusters. Pod is the newest cluster and offers greater capabilities, but Knot is still adequate for most analysis needs and typically has less active users (i.e., a shorter job queue). 1.1 On campus The clusters can be accessed on campus via a terminal emulator using the ssh command or via a GUI SSH app, such as X2Go. On macOS or Linux the default terminal apps can be used. On Windows the PuTTY or X2Go apps can be used. Once a terminal is started, connect to Knot by entering the command $ ssh user@eddie.ecdf.ed.ac.uk where user is your server username. You will then be prompted for your password. SSH keys can also be set up to skip password entry. To use GUI applications on the server, a slightly different process is needed in order to enter an XWindows environment. On macOS, XQuartz must be installed. On Windows, use the X2Go app to connect to the server. More info on X2Go can be found at http://csc.cnsi.ucsb.edu/docs/using-x2go-gui-login-knot-or-pod. To use GUIs, add the -X option to the ssh command, such as $ ssh -X user@eddie.ecdf.ed.ac.uk Once connected, you will interact with the Linux server using the command line interface. The default working directory is your home folder /home/user. Note that this is the login node, but all analyses should be run on compute nodes. These analyses should be submitted as jobs to the queue (more about this later), which allocates compute nodes among users. To disconnect from the cluster, use the command exit. 1.2 Off campus The clusters can be accessed off campus using the VPN service for secure remote access. Instructions for installing the VPN app can be found at https://www.ed.ac.uk/information-services/computing/desktop-personal/vpn. Once the forticlient app is installed, open it and select connect for Remote Access. You will then be prompted to enter your userid and the associated password. Once connected, indicated by a green checkmark, you can then access a cluster as you normally would on campus by using a terminal or GUI SSH app. 1.2.1 More about VPN Note that forticlient VPN could be installed on Linux machine. More details could be found here: "],
["managing-files.html", "2 Managing files 2.1 Navigation 2.2 Viewing, creating, and editing files 2.3 Permissions 2.4 Shortcuts", " 2 Managing files Both Pod and Knot allow for 4 TB of file storage per user and more can be requested if needed. File management on the server clusters involves commonly used Linux commands to navigate and modify files and folders. The generic setup is $ command [options] &lt;arguments&gt; Most of the following commands have multiple options that are not covered here. For detailed documentation enter the command man &lt;command&gt;. Additionally, for a broader introduction to Linux commands see the Software Carpentry’s lessons at http://swcarpentry.github.io/shell-novice/. 2.1 Navigation pwd - present working directory cd dir - change directory (dir specifies directory path) cd - change to home directory (/home/user) cd .. - change to directory above current directory ls - list all files in current directory ls -a - list all files, including hidden files ls -l - list all files with permission information cp source destination - copy file mv source destination - move file mkdir name - make directory mkdir -m 770 name - make directory with permissions (770 or other number) rm file - remove file rmdir dir - remove empty directory (equivalent to rm -d dir) rm -r dir - remove non-empty directory shred -uz file - securely overwrite and delete file 2.2 Viewing, creating, and editing files file file.txt - view file type information stat file.txt - view file information more file.txt - view text file one screen at a time (to exit press q) less file.txt - view text file with scrolling (to exit press q) head file.csv - print first ten rows of text file tail file.csv - print last ten rows of text file head -1 file.csv - print column names if in first row of text file cut -d , -f 2,4-6 file.csv | less - view specific columns of CSV file by number position (e.g., 2,4-6) To view CSV files with pretty output, enter cat file.csv | sed -e 's/,,/, ,/g' | column -s, -t | less -#5 -N -S Note: This may not work well for all files. Use arrow keys to navigate and press q to exit. cat &gt; file.txt - create new text file (to save and exit press Ctrl+D) nano - create new text file using nano text editor nano file.txt - view and edit text file using nano text editor zip -r file.zip file1 folder1 - create compressed ZIP file with recursion unzip file.zip - extract ZIP file into working directory 2.3 Permissions Sometimes file and folder permissions need to be modified, such as to restrict access to files. On Linux, read, write, and execute permissions are represented by octal notation and applied to the file owner, groups, and all other users. # Permission rwx 7 read, write, and execute rwx 6 read and write rw- 5 read and execute r-x 4 read only r– 3 write and execute -wx 2 write only -w- 1 execute only –x 0 none — Common permissions include -rwxrwx--- = 770 - owner and group can do everything, but others can do nothing -rwxr-x--- = 750 - owner can do everything, group can read and execute only, but others can do nothing -rwx------ = 700 - owner can do everything, but group and others can do nothing To change permissions enter chmod 770 dir - change permissions for file or directory chmod -R 770 dir - change permissions recursively for directory chgrp group file - change group ownership for file or directory 2.4 Shortcuts Ctrl+A - move to beginning of line Ctrl+E - move to end of line Ctrl+U - clear line from cursor Ctrl+C - cancel command ~ - home directory . - current directory .. - one directory up * - wildcard completion Tab key - autocompletion Up and down arrow keys - cycle through command history "],
["transferring-files.html", "3 Transferring files 3.1 Using scp to transfer files 3.2 Using rsync to transfer files 3.3 Using rclone to transfer files", " 3 Transferring files To transfer files between a server and your local computer, use scp or rsync commands in the terminal or use a SFTP GUI app. On macOS, Cyberduck and FileZilla are good options. On Windows, WinSCP, Cyberduck, and FileZilla are good options. On Linux, FileZilla is a good option. Another option is to use Globus Online, a web app focused on large file transfers that allows pauses and breaks without loss of data. 3.1 Using scp to transfer files The scp command provides secure copying of files. For more detailed documentation enter the command man scp. The generic setup for an scp command is $ scp [options] &lt;source&gt; &lt;destination&gt; To copy a single file from a local computer to the Pod cluster, the scp command is $ scp /path/to/file.txt user@eddie.ecdf.ed.ac.uk:/home/user To copy an entire directory from a local computer to the Pod server cluster, the typical scp command is $ scp -r /path/to/project user@eddie.ecdf.ed.ac.uk:/home/user where the -r option indicates that files should be transferred recursively, such as subdirectories. 3.2 Using rsync to transfer files The rsync command line tool provides fast, incremental file transfer. The primary use case for rsync is to sync two folders, such as a synced backup folder. Compared to scp, rsync only transfers modified or new files and may also use partial transfers. As a result, rsync is typically faster than scp and SFTP, depending on the options used. For more detailed documentation enter the command man rsync or see https://rsync.samba.org/. On macOS and Linux, rsync is typically pre-installed. On Windows, you will need to install and use rsync via Cygwin. The generic setup for an rsync command is $ rsync [options] &lt;source&gt; &lt;destination&gt; To transfer an entire directory from a local computer to the Pod cluster, a typical rsync command with commonly used options is $ rsync -avzP -e ssh /home/user/project/ user@eddie.ecdf.ed.ac.uk:/home/user/project This example represents a push transfer. A pull transfer could also be completed by simply switching the source and destination. When transferring entire directories, a forward slash on the source matters but never for the destination. In this case, the ‘project’ folder has a forward slash and all its contents will be replicated exactly in the destination ‘project’ folder, copying all contents except the top ‘project’ folder. Without the forward slash on the source there would be another ‘project’ folder within the ‘project’ folder at the destination. The rsync options can be specified in short or long forms. In this use case, the -a or --archive option completely replicates all folders and files, including recursively through all subdirectories while preserving symbolic links, permissions, and ownership. The -v or --verbose option increases the amount of information that is logged. The -z or --compress option compresses files during transit to reduce transfer time. The -P or --partial --progress option enables partially transferred files to be kept in case of a break or pause and also displays the progress of individual file transfers. The -e ssh option instructs rysnc to transfer files via SSH, used when transferring to or from a server. Many other options exist, but these are the primary ones used. Additionally, add the -n or --dry-run option to test what an rsync command will do without actually transferring files. After the command is submitted, you will be prompted for a password if transferring to or from a server. If you use rsync frequently, then you can also set up SSH keys in order to skip password entry. For large transfers, sometimes the process needs to be paused and resumed, or sometimes the transfer can be interrupted due to a server, network, or power outage. The -P option should always be used to preserve the files or parts of files that have already been transferred and to avoid having to start over. To pause a transfer, use Ctrl+C. To resume, resubmit the same rsync command with the --append option added, which will restart the transfer where it left off. When syncing to a backup folder, add the --delete option to delete files and folders in the destination that have been deleted in the source. 3.3 Using rclone to transfer files The rclone command line tool transfers files to and from cloud storage services, like UCSB-provided unlimited Google Drive or Box storage. rclone is designed after rsync and its commands look similar. You will need to configure rclone so that it can access your cloud storage services. For detailed documentation see https://rclone.org/. "],
["submitting-jobs.html", "4 Submitting jobs 4.1 Knot 4.2 Pod", " 4 Submitting jobs The server clusters are shared resources among researchers, and a job queue process is used to manage and allocate resources among users. A job is simply a set of instructions that includes requests for resources and the specific set of commands—typically as scripts—to be executed, such as commands for transforming or analyzing data. When a user submits a job to the server for execution it enters the queue and is scheduled on a specific compute node for a specific time. 4.1 Knot The Knot cluster has 112 regular compute nodes with 12 cores per node and either 48 GB or 64 GB of RAM per node. There are also 4 ‘fat’ nodes with either 512 GB or 1 TB of RAM and 6 GPU nodes. Knot uses TORQUE PBS to schedule jobs. To submit a job, first create a new .pbs file with the nano editor using the command $ nano submit.pbs The typical structure of a .pbs file for a serial job using R is #!/bin/bash #PBS -l nodes=1:ppn=1 #PBS -l walltime=2:00:00 #PBS -V cd $PBS_O_WORKDIR Rscript --vanilla script.R where 1 node with 1 processor is requested with a 2-hour timeframe for computation. The walltime option can be excluded if the computation time is unknown. The default walltime is 75 hours. The cd $PBS_O_WORKDIR changes the working directory to where the .pbs file is located. The Rscript --vanilla script.R line executes the commands in the specified R script. The filepath for the script should be relative to where the .pbs file is located or an absolute path can also be used. This line would change if using different software. There are also many other #PBS options that can be included. Parallel jobs require different specifications, such as requesting more than 1 node and using mpirun commands. Also be sure to include a blank line at the end of the file. To submit a job, use the command $ qsub submit.pbs For jobs that require less than one hour or are used for testing and debugging purposes, use the short queue to minimize waiting time with the command $ qsub -q short submit.pbs For jobs that require large memory, use the command $ qsub -q largemem submit.pbs for nodes with 256 GB/node or the command $ qsub -q xlargemem submit.pbs for nodes with 512 GB/node. The qsub command will return a job number. To check the status of a job, use the command $ qstat &lt;job number&gt; or $ qstat -u $USER To cancel or delete a job, use the command $ qdel &lt;job number&gt; The outputs of the analysis in the script will be returned in the same folder as the .pbs file that was submitted, typically with the filename structure submit.pbs.[job number] unless otherwise specified. 4.2 Pod The Pod cluster is the newest on campus and offers the most compute resources. There are 64 regular compute nodes with 40 cores per node and 192 GB of RAM per node. There are also 4 ‘fat’ nodes with 1 TB of RAM per node and 3 GPU nodes. Pod uses SLURM to schedule jobs. To submit a job, first create a new .job file with the nano editor using the command $ nano submit.job The typical structure of a .job file for a serial job using R is #!/bin/bash -l #SBATCH --nodes=1 --ntasks-per-node=1 #SBATCH --time=2:00:00 cd $SLURM_SUBMIT_DIR module load R Rscript --vanilla script.R where 1 node with 1 processor is requested. The cd $PBS_O_WORKDIR changes the working directory to where the .job file is located. The module load R line loads R, and then the Rscript --vanilla script.R line executes the commands in the specified R script. The filepath for the script should be relative to where the .job file is located or an absolute path can also be used. These last two lines would change if using different software. There are also many other #SBATCH options that can be included. The default walltime for computation is 32 hours. Parallel jobs require different specifications, such as requesting more than 1 node and using mpirun commands. Also be sure to include a blank line at the end of the file. To submit a job, use the command $ sbatch submit.job For jobs that require less than one hour or are used for testing and debugging purposes, you can use the short queue to minimize waiting time with the command $ sbatch -p short submit.job For jobs that require large memory, use the command $ sbatch -p largemem submit.job for nodes with 1 TB/node. The sbatch command will return a job number. To check the status of a job, use one of the commands $ squeue -j &lt;job number&gt; or $ squeue -u $USER To cancel or delete a job, use the command $ scancel &lt;job number&gt; The outputs of the analysis in the script will be returned in the same folder as the .job file that was submitted, typically with the filename structure slurm-[jobnumber].out unless otherwise specified. "],
["using-private-modules.html", "5 Using Private Modules", " 5 Using Private Modules It would be slightly different from other HPC platform, when we want to use our own module, we will have to You will have three steps to go: - Install the software by making with binary files (note: ./configure --prefix=/home/path) - Make Private Module files inside the private module path $MODULEPATH - (export MODULEPATH=$HOME/privatemodules:$MODULEPATH) - Private Module file format could be found in the following example - Module load as ususal: `module load package/version_num ## Example of python 3.10 Install python 3.10 from official website (skip) Configure HPC (just do it once) vim .bashrc add export MODULEPATH=$HOME/privatemodules:$MODULEPATH source .bashrc Add ~/privatemodules/python/3.10 #%Module######################################################################## # # python 3.10.4 module file proc ModulesHelp { } { puts stderr &quot;\\tAdds python 3.10.4 to your environment&quot; } module-whatis &quot;Loads Python 3.10.4&quot; prepend-path PATH ~/src/bin prepend-path LD_LIBRARY_PATH ~/src/lib prepend-path C_INCLUDE_PATH ~/src/include prepend-path PKG_CONFIG_PATH ~/src/lib/pkgconfig prepend-path MANPATH ~/src/share/man prepend-path PYTHONPATH ~/src/lib/python3.10 Module load: module load python/3.10 Now it is really to go :) "],
["wiki-example.html", "6 Wiki + Example 6.1 Example: Using R", " 6 Wiki + Example From wiki, it provides a few guidance of using R, Tensorflow, Matlab, Java, Python, Singularity. 6.1 Example: Using R R is available on both Knot and Pod, including different versions of R. 6.1.1 Loading R To load R on Knot for interactive use, enter the command $ R To load R on Pod for interactive use, enter the commands $ load module R $ R To exit R, use the command q(). Note that the RStudio IDE is not available for use on the clusters. Remember: Most analyses should be performed on compute nodes by submitting batch jobs. The login node should only be used for simple analyses, testing, or debugging. 6.1.2 Versions On Knot, the available version of R is 3.2.2. On Pod, the available versions of R include R/3.2.2 R/3.4.4 R/3.5.1-multith R/3.5.1 The default is the latest version. To load a specific version, for example, use the command load module R/3.4.4. A different version of R can be installed inside your home directory. For more info see http://csc.cnsi.ucsb.edu/docs/using-r-knot-braid-and-pod. 6.1.3 Packages Packages can be installed using the R command install.packages(&quot;&lt;package&gt;&quot;) and should be stored inside your home folder. When using this command you may be prompted to select a CRAN mirror from which to download; select a USA (CA) mirror with an HTTPS connection for a fast and secure download. R should automatically add the home-based package library to .libPaths() (enter this command to confirm) and set it as default. 6.1.4 Example job files 6.1.4.1 Knot #!/bin/bash #PBS -l nodes=1:ppn=1 #PBS -l walltime=2:00:00 #PBS -m abe #PBS -M user@ucsb.edu cd $PBS_O_WORKDIR Rscript --vanilla script.R 6.1.4.2 Pod #!/bin/bash -l #SBATCH --nodes=1 --ntasks-per-node=1 #SBATCH --time=2:00:00 #SBATCH --mail-type=ALL #SBATCH --mail-user=user@ucsb.edu cd $SLURM_SUBMIT_DIR module load R Rscript --vanilla script.R "],
["using-software-containers.html", "7 Using software containers", " 7 Using software containers Software containers can be used on the server clusters via Singularity. Containers enable fully reproducible research by packaging a computing environment and the necessary software packages and applications as a self-contained image file that can be easily transferred to and run on other systems. Containers are also useful for collaborating across different institutions and computing infrastructures. Find out more information at http://csc.cnsi.ucsb.edu/docs/containers. "],
["gpu-usage.html", "8 GPU Usage 8.1 Quick Start 8.2 Advanced Usage (Adapted from BU.EDU) 8.3 Ask for help", " 8 GPU Usage This section is a quick guide of using GPU nodes. More details could be found from here. Hey futuer researchers, if you want to train a Neural Net, here might be the right place! I had also struggled a bit when I first got started. 8.1 Quick Start The quickest way is to login to GPU nodes and run code on top of that. qlogin -l h_rt=24:00:00 -l h_vmem=16G -pe gpu 4 8.2 Advanced Usage (Adapted from BU.EDU) I found this University https://www.bu.edu/engit/knowledge-base/grid/gpu/ had a simliar cluster system as we have in Eddie. Here is the tutorial adapted from that website in case it will disappear. 8.2.1 GPU-enabled Grid queues The current GPU-enabled queues on the ENG-Grid are: Skill this. gpu.q -- 1 GPU and 2 CPU cores per 4GB RAM workstation node Currently 16 nodes with a total of 16 GeForce Kepler GTX 650 (2GB) GPUs (they additionally have small Quadro NVS GPUs (256MB) attached to the displays, not really useful for CUDA) budge.q -- 8 GPUs and 8 CPU cores per 24GB RAM per node Currently 2 nodes with a total of 16 GPUs: 8 non-Fermi Tesla M1060&#39;s (4GB), 6 Tesla Fermi M2050&#39;s, and 2 Tesla Fermi M2090&#39;s (6GB) bungee.q -- 2 or 3 GPUs and 8 CPU cores per 24GB RAM node, with QDR InfiniBand networking Currently 3 nodes with 1 Tesla Kepler K20 (6GB) and 2 Tesla Fermi M2070/2075&#39;s (6GB) each, plus 13 nodes with 2 Tesla Fermi M2070/2075&#39;s (6GB) each. (Divided into bungee.q and bungee-exclusive.q for use by buy-in researchers) gpuinteractive.q -- a subset of budge.q intended for GPU but not CPU-intensive &quot;qlogin&quot; jobs If you wish to be added to the permissions list to use these queues, please email. 8.2.2 Using GPU resources For GPU submission on the Grid, we have configured a consumable resource complex called “gpu” on these queues. Each host has an integer quantity of the gpu resource corresponding to the number of GPUs in it. Machines with Fermi and Kepler-generation GPUs have the boolean resources “fermi” and “kepler”, as well. To see the status of arbitrary complex resources on the queue, use qstat with the -F switch, like this: qstat -q bungee.q,budge.q,gpu.q -F gpu,fermi,kepler Note that previous command is not working well in Eddie, see below qstat -q gpu -F gpus,gputype,mem_total If you submit to any gpu-enabled queue and intend to use the GPU for computation, you should submit with the switch “-l gpu=1”. Thus, if you were to run, for example: cd /mnt/nokrb/yourusername qsub -q bungee.q -cwd -l gpu=1 -b y &quot;./mycudaprogram&quot; That will pick a node in the gpu.q queue that has the gpu resource free, and will consume its resource. The machine still has another “slot” available for use by a qsub that does not request the gpu. Since there are 16 machines in the gpu.q queue with 2 CPUs each but only 1 GPU each, there are 32 slots total but only 16 slots of GPU. So if all the slots were empty, and you submit 17 jobs that each request “-l gpu=1”, the jobs will go to 16 hosts and one will wait in the queue for one of the jobs to finish so that a gpu frees up. So if you submit 16 jobs that each request a GPU and 16 that don’t, then they will all execute simultaneously and nothing will wait in the queue. For the bungee.q, there are 128 slots, because there are 8 cores in each bungee machine x 16 machines, but there are only 32 resources in the “gpu” complex, because there are 2 gpus in each bungee machine x 16 machines. If you specifically wanted two Fermi GPUs on the bungee.q, you would run: qsub -q bungee.q -cwd -l gpu=2 -l fermi=true -b y &quot;./mycudaprogram&quot; If you wanted to specifically avoid Fermi GPUs, you would use fermi=false. If you don’t care what kind of GPU you get, you would not bother putting the fermi= switch in there at all. Please do not request a gpu resource in the queue if you do not intend to use the gpu for that job, and likewise, please do not attempt to use the gpu in the queue without requesting the gpu resource — it will only slow things down for you to try have more GPU jobs running than you have GPUs in the system. Note that specifying “gpu=2” doesn’t actually change whether your code is allowed to use 2 GPUs or one — the “gpu” complex is just basically an honor system. It makes it so that you’ve “reserved” both GPUs on that machine for your own work, and as long as other people who are using 1 or 2 gpus also make sure to specify gpu=1 or gpu=2 accordingly, nobody should conflict. Of course, as soon as someone starts using gpu code without having reserved a gpu, this accounting doesn’t help anymore, so if you intend to use a gpu, please make sure to always request the complex. Likewise, if you request an interactive slot, make sure to “qlogin” to gpuinteractive.q and never to ssh directly into machines in the queue: qlogin -q gpuinteractive.q -l gpu=1 (for an interactive login where you intend to run GPU code) or qlogin -q gpu.q (for an interactive login where you do not intend to use the GPU. NOTE WELL -- there&#39;s really no reason to do this! For a basic login where you don&#39;t intend to use the GPU, there&#39;s no reason to use gpuinteractive.q at all -- use another queue that has far more slots in it, such as interactive.q!) 8.2.3 EXAMPLE: Submitting a CUDA Job through qsub We recommend that once you’re running production jobs, you submit batch jobs (qsub) instead of interactive jobs (qlogin). Refer to Grid Cuda for step-by-step instructions on building a CUDA program in our environment, test your code on the command line, and then read below to batch it up. Set up Grid Engine as described at Grid Instructions , and write a shell script to include all of the switches you wish to use, putting both it and the binary you wish to run in your /mnt/nokrb directory. #$ -V #$ -cwd #$ -q budge.q #$ -l fermi=false #$ -l gpu=1 #$ -N yourJobName #$ -j y ./yourCudaBinary Now change to the /mnt/nokrb/yourusername directory where you put both the script and binary, and run: qsub gridrun.sh You could alternatively forego the shell script and put all of the switches on the command line, like this, but this gets unwieldy when there are too many options: qsub -q qsub -V -cwd -q budge.q -l fermi=false -l gpu=1 -N yourJobName -j y -b y &quot;./yourCudaBinary&quot; Note that this script uses the “-V” switch to put all of the libraries sourced in your current shell into the remote shell, and the “-j y” switch to join stdout (.o files) and stderr (.e files), and that it uses the “budge.q” and asks for one non-Fermi GPU. You could use the other queues, including bungee.q, if you need different features. 8.2.4 Submitting a CUDA Job with an nvidia-smi operation The gpu complex only reports the number of available GPUs on a node, trusting the users to have requested GPUs honestly using “-l gpu=#”. For more information, you can use deviceQuery or nvidia-smi, which report real-time GPU statistics. For deviceQuery, follow the instructions at http://www.resultsovercoffee.com/2011/02/cudavisibledevices.html Here is an example for using nvidia-smi to do something similar — to check available GPU memory on each GPU in the system and passes back the device number of the unloaded GPU which you could then use as an argument to your binary to run cudaSetDevice. #$ -cwd hostname dev=`nvidia-smi -a | grep Free | awk &#39;{print $3}&#39;|./choose_device.sh` ./command -device $dev So just incorporate this into your own submission script and use it to pass an argument to your program to setCudaDevice appropriately. So, note that bungee.q has 2 GPUs per node and budge.q has 8, and in the third submission I specifically asked for Fermis: bungee:/mnt/nokrb/kamalic$ qsub -q bungee.q nvidiamem.sh Your job 2334109 (&quot;nvidiamem.sh&quot;) has been submitted bungee:/mnt/nokrb/kamalic$ qsub -q budge.q nvidiamem.sh Your job 2334110 (&quot;nvidiamem.sh&quot;) has been submitted bungee:/mnt/nokrb/kamalic$ qsub -q bungee.q -l fermi=true nvidiamem.sh Your job 2334113 (&quot;nvidiamem.sh&quot;) has been submitted bungee:/mnt/nokrb/kamalic$ more nvidiamem.sh.o* :::::::::::::: nvidiamem.sh.o2334109 :::::::::::::: bungee16 4092 4092 :::::::::::::: nvidiamem.sh.o2334110 :::::::::::::: budge02.bu.edu 4092 4092 4092 4092 4092 4092 4092 4092 :::::::::::::: nvidiamem.sh.o2334113 :::::::::::::: bungee05 5365 5365 Below is an example on a machine which has two CUDA cards, showing how to use the CUDA_VISIBLE_DEVICES variable to show only one of the two devices, query it to see that it’s the only one showing up, and then running on that device: hpcl-19:~/Class/cuda/cudademo$ /ad/eng/support/software/linux/all/x86_64/cuda/cuda_sdk/C/bin/linux/release/deviceQuery -noprompt|egrep &quot;^Device&quot; [deviceQuery] starting... Device 0: &quot;D14P2-30&quot; Device 1: &quot;Quadro NVS 295&quot; [deviceQuery] test results... PASSED NOTE that on some platforms, “nvidia-smi” actually MISREPORTS the device numbers! It’s best to use deviceQuery, or to sanity-check what’s being reported! [So we see both devices. Now we set only the first device visible:] hpcl-19:~/Class/cuda/cudademo$ export CUDA_VISIBLE_DEVICES=&quot;0&quot; hpcl-19:~/Class/cuda/cudademo$ /ad/eng/support/software/linux/all/x86_64/cuda/cuda_sdk/C/bin/linux/release/deviceQuery -noprompt|egrep &quot;^Device&quot; [deviceQuery] starting... Device 0: &quot;D14P2-30&quot; [deviceQuery] test results... PASSED hpcl-19:~/Class/cuda/cudademo$ ./cudademo [SNIP] 9.000000 258064.000000 259081.000000 260100.000000 261121.000000 [Now we set only the second device visible:] hpcl-19:~/Class/cuda/cudademo$ export CUDA_VISIBLE_DEVICES=&quot;1&quot; hpcl-19:~/Class/cuda/cudademo$ /ad/eng/support/software/linux/all/x86_64/cuda/cuda_sdk/C/bin/linux/release/deviceQuery -noprompt|egrep &quot;^Device&quot; [deviceQuery] starting... Device 0: &quot;Quadro NVS 295&quot; [deviceQuery] test results... PASSED hpcl-19:~/Class/cuda/cudademo$ ./cudademo [SNIP] 9.000000 258064.000000 259081.000000 260100.000000 261121.000000 hpcl-19:~/Class/cuda/cudademo$ Note that for a program as small as cudademo, any difference in speed between the two cards is meaningless. 8.3 Ask for help Mike is really helpful when I was here. Every Thursday from 2-4 PM in 2022, we will be able to ask questions with Teams. You will be able to receive an email from Mike at that time :) "]
]
